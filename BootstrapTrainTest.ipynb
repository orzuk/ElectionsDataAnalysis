{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: -0.0017937751453583894\n",
      "Std: 0.029046680150334965, Theoretical std: 0.028867513459481284\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Bootstrap Example: \n",
    "n = 100 # number of samples\n",
    "iters = 500  # iterations for estimating standard deviations\n",
    "mu_vec = np.zeros(iters)\n",
    "\n",
    "for i in range(iters):\n",
    "    v = np.random.rand(n, 1)\n",
    "    mu_vec[i] = np.mean(v)  # average is estimator of mean \n",
    "    \n",
    "print(\"Bias: \" + str(np.mean(mu_vec)-0.5))\n",
    "print(\"Std: \" + str(np.std(mu_vec)) + \", Theoretical std: \" + str(1.0 / np.sqrt(12.0*n)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap function\n",
    "def Bootstrap(x, n=-1):\n",
    "    if n == -1:\n",
    "        n = x.shape[0]\n",
    "    return x[np.random.choice(x.shape[0],n),] # sample from x \n",
    "\n",
    "v = np.array([1,2,3,4])\n",
    "print(Bootstrap(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Std: 0.027886338774107157, Theoretical std: 0.028867513459481284\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# An estimator of mu from a sample\n",
    "def mean_estimator(x):\n",
    "    return np.mean(x)\n",
    "    \n",
    "# Compute bootstrap standad deviation\n",
    "def Bootstrap_std(x, estimator, bootstrap_iters):\n",
    "    theta_vec = np.zeros(bootstrap_iters)\n",
    "    for i in range(bootstrap_iters):\n",
    "        theta_vec[i] = estimator(Bootstrap(x))\n",
    "    return np.std(theta_vec) # This is the bootstrap estimate of the standard deviation \n",
    "\n",
    "\n",
    "# Compute standard deviation using the bootstrap \n",
    "v = np.random.rand(n, 1)\n",
    "bootstrap_iters = 500\n",
    "bootstrap_std = Bootstrap_std(v, mean_estimator, bootstrap_iters)\n",
    "print(\"Bootstrap Std: \" + str(bootstrap_std) + \", Theoretical std: \" + str(1.0 / np.sqrt(12.0*n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# Train test example \n",
    "# load Boston housing dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213 481 364 386  53 252 290 263 440 337 143 114 346  51 429 374 460 282\n",
      " 192  30 323  76 241 232  14 142 348 216 102 365 111 163 452 235 266  89\n",
      " 396 505 403 439  83  36 456 268 121 117  85 115 393 196 492 497 335 279\n",
      " 184 137 488 428 495 357 416  70 147 443 463 283 410 243 466 284  29 209\n",
      " 320  22 303 436 381 392 453 368 325 496 399   7 430  48  88 486  38 269\n",
      " 240 206 356  32 427   1 159 457 190 401 198]\n",
      "[0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 31, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 191, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 207, 208, 210, 211, 212, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 236, 237, 238, 239, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 264, 265, 267, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 324, 326, 327, 328, 329, 330, 331, 332, 333, 334, 336, 338, 339, 340, 341, 342, 343, 344, 345, 347, 349, 350, 351, 352, 353, 354, 355, 358, 359, 360, 361, 362, 363, 366, 367, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 382, 383, 384, 385, 387, 388, 389, 390, 391, 394, 395, 397, 398, 400, 402, 404, 405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 437, 438, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 454, 455, 458, 459, 461, 462, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 483, 484, 485, 487, 489, 490, 491, 493, 494, 498, 499, 500, 501, 502, 503, 504]\n"
     ]
    }
   ],
   "source": [
    "# divide to train/test: \n",
    "test_prop = 0.2 \n",
    "n = X.shape[0]\n",
    "\n",
    "test_ind = np.random.choice(n, round(test_prop*n), replace=False)\n",
    "train_ind = list(set(range(n)).difference(test_ind))\n",
    "print(test_ind)\n",
    "print(train_ind)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Error: 21.84131276000921\n",
      "Average Test Error: 23.33229583498381\n"
     ]
    }
   ],
   "source": [
    "split_iters = 100 # random splits to train and test \n",
    "\n",
    "train_error = 0\n",
    "test_error = 0\n",
    "for i in range(split_iters):\n",
    "    test_ind = np.random.choice(n, round(test_prop*n), replace=False)\n",
    "    train_ind = list(set(range(n)).difference(test_ind))\n",
    "#    print(test_ind)\n",
    "#    print(train_ind)\n",
    "     \n",
    "    # Fit model for train: \n",
    "    reg = LinearRegression().fit(X[train_ind,], y[train_ind])\n",
    "\n",
    "    y_train_hat = reg.predict(X[train_ind,])\n",
    "    train_error += np.mean((y_train_hat - y[train_ind])**2)\n",
    "\n",
    "    y_test_hat = reg.predict(X[test_ind,])\n",
    "    test_error += np.mean((y_test_hat - y[test_ind])**2)\n",
    "\n",
    "    \n",
    "print(\"Average Train Error: \" + str(train_error/split_iters))\n",
    "print(\"Average Test Error: \" + str(test_error/split_iters))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
